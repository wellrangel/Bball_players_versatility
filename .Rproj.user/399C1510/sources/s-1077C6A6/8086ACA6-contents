#model_id mean_per_class_error
#1    DeepLearning_grid_0_AutoML_20180517_075319_model_2         0.3080599689
#2 StackedEnsemble_BestOfFamily_0_AutoML_20180517_075319         0.3113437440
#3             GBM_grid_0_AutoML_20180517_075319_model_7         0.3267283594
#4    DeepLearning_grid_0_AutoML_20180517_075319_model_0         0.3621708116
#35             GLM_grid_0_AutoML_20180517_075319_model_0         0.3680728972
#6             GBM_grid_0_AutoML_20180517_075319_model_3         0.3722498554

library(h2o)

source("scripts/functions.R")

h2o.init(nthreads = -1)
options(scipen=20)

dfstats <- readData();
dfstats <-dfstats[dfstats$played_minutes > 100,]
unique(dfstats$pos)


dfstats$pos <- as.factor(dfstats$pos)

options(digits=10)

training <- getTreinoData(dfstats)
validation <- getValidacaoData(dfstats)
test <- getTesteData(dfstats)

training.hex  <- as.h2o(training) # convertendo df para formato h2o
validation.hex  <- as.h2o(validation) 
test.hex  <- as.h2o(test)

table(test$equipe,test$pos)

alldata.hex  <- as.h2o(dfstats) 

x <- c(
  "made_two_points", "lost_two_points", 
  "made_three_points", "lost_three_points", 
  "made_free_throw_points" , "lost_free_throw_points",
  "dunk_points", "steals","total_assists",
  "offensive_rebounds","defensive_rebounds",
  "commited_fouls", "received_fouls")

y <- "pos"


aml <- h2o.automl(x = x, y = y,
                  training_frame = training.hex,
                  seed = 123,
                  #balance_classes = T,
                  validation_frame=validation.hex, 
                  leaderboard_frame = test.hex, # com 0.7045454545, sem esse parametro 0.7196969697
                  stopping_metric = "mean_per_class_error",
                  max_runtime_secs = 60)

# View the AutoML Leaderboard
lb <- aml@leaderboard
lb

# The leader model is stored here
aml@leader
class(aml@leader)

# save the model
model_path <- h2o.saveModel(object=aml@leader, path="ml_model/model", force=TRUE)

my_varimpRF <- h2o.varimp(aml@leader)

print(model_path)



# If you need to generate predictions on a test set, you can make
# predictions directly on the `"H2OAutoML"` object, or on the leader
# model object directly

pred <- h2o.predict(aml, validation.hex)   # predict(aml, test) also works
mean(pred$predict==validation.hex$pos)





confusion_matrix <- test_performance %>% select(-correct) %>% table() 
confusion_matrix

sum(confusion_matrix)
diag = diag(confusion_matrix)

accuracy = sum(diag) / sum(confusion_matrix)


dataset_pred_test <- as.data.frame(pred)
final_test <- cbind(dataset_pred_test, test ) 

#write.csv(final_test, file = "output/final_test.csv")




perf <- h2o.performance(aml@leader, test.hex)

h2o.confusionMatrix(perf)



h2o.accuracy(perf)

perf <- h2o.performance(aml@leader, validation.hex)
h2o.confusionMatrix(perf)


pred_todos <- h2o.predict(aml, alldata.hex)   # predict(aml, test) also works
mean(pred_todos$predict==alldata.hex$pos)

dataset_pred_todos <- as.data.frame(pred_todos)

final_todos <- cbind(dataset_pred_todos,  dfstats) 

#write.csv(final_todos, file = "output/final_todos.csv")


# load the model
saved_model <- h2o.loadModel(model_path)
predload <- h2o.predict(saved_model, test.hex)  
mean(predload$predict==test.hex$pos)

predload <- h2o.predict(aml@leader, alldata.hex)  
mean(predload$predict==alldata.hex$pos)


#h2o.shutdown(prompt=FALSE)




model_ids <- as.data.frame(aml@leaderboard$model_id)[,1]
# Get the "All Models" Stacked Ensemble model
se <- h2o.getModel(grep("StackedEnsemble_BestOfFamily_0_AutoML_20180517_114023", model_ids, value = TRUE)[1])
se <- h2o.loadModel("StackedEnsemble_BestOfFamily_0_AutoML_20180507_090457")
# Get the Stacked Ensemble metalearner model

pred <- h2o.predict(se, test.hex)   # predict(aml, test) also works
mean(pred$predict==test.hex$pos)


test_performance <- test %>%
  tibble::as_tibble() %>%
  select(pos) %>%
  tibble::add_column(posFinal = as.vector(pred$predict)) %>%
  mutate(correct = ifelse(pos == posFinal, "correct", "wrong")) %>% 
  mutate_if(is.character, as.factor)

head(test_performance)



confusion_matrix <- test_performance %>% select(-correct) %>% table() 
confusion_matrix

sum(confusion_matrix)
diag = diag(confusion_matrix)

accuracy = sum(diag) / sum(confusion_matrix)


### Performance analysis ####
tn <- confusion_matrix[1]
tp <- confusion_matrix[4]
fp <- confusion_matrix[3]
fn <- confusion_matrix[2]


accuracy <- (tp + tn) / (tp + tn + fp + fn)
misclassification_rate <- 1 - accuracy
recall <- tp / (tp + fn)
precision <- tp / (tp + fp)
null_error_rate <- tn / (tp + tn + fp + fn)



120/
library(purrr)


tibble(
  accuracy,
  misclassification_rate,
  recall,
  precision,
  null_error_rate
) %>% 
  purrr::transpose() 

library(lime)



x <- c("pos", "jogador",  "tried_two_points", "two_points", "lost_two_points", "wrong_throws", 
  "tried_three_points", "three_points","dunk_points","tried_free_throw_points", "free_throw_points", 
  "steals","total_assists","offensive_rebounds","defensive_rebounds","commited_fouls", "received_fouls")




test_pred  <- test[,x]

test_h2o_df = as.data.frame(test_pred)

test_h2o_2 = test_h2o_df %>%
  as.data.frame() %>% 
  mutate(sample_id = rownames(test_h2o_df ))



test_final<- cbind(test_h2o_df,  test_performance) 
test_correct <- test_final[test_final$correct=="correct",]


test_wrong <- test_final[test_final$correct!="correct",]






h2o.shutdown(prompt=FALSE)
